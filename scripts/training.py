"""
Complete AQI Prediction Model Training Pipeline
Includes data fetching, preprocessing, model training, and evaluation
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
import statsmodels.api as sm
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit
import xgboost as xgb
import pickle
import joblib
import hopsworks
import os
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# SECTION 1: FETCH DATA FROM HOPSWORKS
# =============================================================================
def fetch_from_hopsworks(feature_group_name="aqi_features", version=1, for_training=False):
    """
    Fetch data from Hopsworks (fallback to local). Handles invalid timestamps and nullable dtypes.
    """
    print("\n" + "="*70)
    print(f"{'FETCHING FROM HOPSWORKS FOR VERIFICATION' if not for_training else 'SECTION 1: FETCHING FEATURES FROM HOPSWORKS'}")
    print("="*70)
    try:
        project = hopsworks.login(api_key_value=os.getenv("HOPSWORKS_API_KEY"))
        fs = project.get_feature_store()
        feature_group = fs.get_feature_group(name=feature_group_name, version=version)
        df = feature_group.read()

        # Convert timestamp back to datetime
        if 'datetime_utc' in df.columns and df['datetime_utc'].dtype == 'int64':
            df['datetime_utc'] = pd.to_datetime(df['datetime_utc'], unit='ms', errors='coerce')
            # Drop rows with invalid timestamps
            invalid_mask = df['datetime_utc'].isna() | (df['datetime_utc'] < pd.Timestamp('1678-01-01')) | (df['datetime_utc'] > pd.Timestamp('2262-04-11'))
            if invalid_mask.sum() > 0:
                print(f"‚ö†Ô∏è Dropped {invalid_mask.sum()} rows with invalid timestamps")
                df = df[~invalid_mask].reset_index(drop=True)
            
            # Fix int dtypes
            int_cols = ['us_aqi', 'hour', 'month', 'day_of_week', 'is_weekend']
            for col in int_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype('int64')

        # Drop 'id' if present
        if 'id' in df.columns:
            df = df.drop('id', axis=1)

        print(f"‚úÖ Fetched from Hopsworks! Shape: {df.shape}")
        print(f"Columns: {list(df.columns)}")
        return df
    except Exception as e:
        print(f"‚ùå Hopsworks fetch failed: {e}. Falling back to local CSV.")
        try:
            df = pd.read_csv('2years_features.csv', parse_dates=['datetime_utc'])
            print(f"‚úÖ Fallback to local CSV! Shape: {df.shape}")
            return df
        except FileNotFoundError:
            raise ValueError("No local CSV found‚Äîensure upload happened first.")

# =============================================================================
# SECTION 2: DATA PREPARATION & SPLITTING
# =============================================================================
def prepare_data(df_feat):
    """
    Prepare features and split data chronologically
    """
    print("\n" + "="*70)
    print("SECTION 2: DATA PREPARATION & SPLITTING")
    print("="*70)

    # Select features based on correlation (exclude leakage columns)
    exclude = ['us_aqi', 'aqi_category', 'id', 'datetime_utc', 'aqi']
    feature_cols = [col for col in df_feat.columns if col not in exclude]
    
    # Calculate correlation with target
    corr = df_feat[feature_cols + ['us_aqi']].corr()['us_aqi'].sort_values(ascending=False)
    selected_features = [f for f in corr.index[1:] if abs(corr[f]) > 0.3]
    
    print(f"‚úÖ Using {len(selected_features)} features: {selected_features}")

    # Prepare X/y
    X = df_feat[selected_features].fillna(0).values
    y = df_feat['us_aqi'].values

    # Chronological split: 70% train, 10% val, 20% test
    split_train = int(0.7 * len(X))
    split_val = int(0.8 * len(X))
    X_train, X_val, X_test = X[:split_train], X[split_train:split_val], X[split_val:]
    y_train, y_val, y_test = y[:split_train], y[split_train:split_val], y[split_val:]

    print(f"üìä Split: Train={X_train.shape}, Val={X_val.shape}, Test={X_test.shape}")

    # Scaling (for non-tree models)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)
    
    # Save scaler
    joblib.dump(scaler, 'scaler.pkl')
    print("‚úÖ Scaling complete!")

    # Save selected features
    with open('selected_features.json', 'w') as f:
        import json
        json.dump(selected_features, f)

    return (X_train, X_val, X_test, y_train, y_val, y_test,
            X_train_scaled, X_val_scaled, X_test_scaled, selected_features)

# =============================================================================
# METRICS CALCULATION
# =============================================================================
def calc_metrics(y_true, y_pred):
    """Calculate MAE, RMSE, R¬≤, and MAPE"""
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)
    
    # Safe MAPE calculation
    mask = y_true != 0
    if np.any(mask):
        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100
    else:
        mape = np.nan
    
    return mae, rmse, r2, mape

# =============================================================================
# SECTION 3: MODEL TRAINING
# =============================================================================
def train_all_models(X_train, X_val, X_test, y_train, y_val, y_test,
                     X_train_scaled, X_val_scaled, X_test_scaled, selected_features):
    """
    Train all 7 models with regularization
    """
    print("\n" + "="*70)
    print("SECTION 3: MODEL TRAINING (7 MODELS WITH REGULARIZATION)")
    print("="*70)
    
    results = {}
    tscv = TimeSeriesSplit(n_splits=5)
    
    # ==================== MODEL 1: Linear Regression ====================
    print("\n1Ô∏è‚É£ Linear Regression (statsmodels)...")
    X_train_sm = sm.add_constant(X_train_scaled)
    model1 = sm.OLS(y_train, X_train_sm).fit()
    X_val_sm = sm.add_constant(X_val_scaled)
    X_test_sm = sm.add_constant(X_test_scaled)
    
    y_train_pred1 = model1.predict(X_train_sm)
    y_val_pred1 = model1.predict(X_val_sm)
    y_test_pred1 = model1.predict(X_test_sm)
    
    mae1_t, rmse1_t, r21_t, mape1_t = calc_metrics(y_train, y_train_pred1)
    mae1_v, rmse1_v, r21_v, mape1_v = calc_metrics(y_val, y_val_pred1)
    mae1, rmse1, r21, mape1 = calc_metrics(y_test, y_test_pred1)
    
    print(f" Train: MAE={mae1_t:.2f}, RMSE={rmse1_t:.2f}, R¬≤={r21_t:.3f}, MAPE={mape1_t:.2f}%")
    print(f" Val:   MAE={mae1_v:.2f}, RMSE={rmse1_v:.2f}, R¬≤={r21_v:.3f}, MAPE={mape1_v:.2f}%")
    print(f" Test:  MAE={mae1:.2f}, RMSE={rmse1:.2f}, R¬≤={r21:.3f}, MAPE={mape1:.2f}% | Gap: {r21_t - r21:.3f}")
    
    # CV R¬≤
    cv_scores1 = []
    for train_idx, val_idx in tscv.split(X_train_scaled):
        X_fold_train = sm.add_constant(X_train_scaled[train_idx])
        fold_model = sm.OLS(y_train[train_idx], X_fold_train).fit()
        X_fold_val = sm.add_constant(X_train_scaled[val_idx])
        fold_pred = fold_model.predict(X_fold_val)
        cv_scores1.append(r2_score(y_train[val_idx], fold_pred))
    cv_r2_1 = np.mean(cv_scores1)
    print(f" CV R¬≤: {cv_r2_1:.3f}")
    
    results['linear'] = {
        'model': model1, 'name': 'Linear Regression',
        'test_r2': r21, 'test_rmse': rmse1, 'test_mae': mae1, 'test_mape': mape1, 'cv_r2': cv_r2_1
    }
    with open('linear_model.pkl', 'wb') as f:
        pickle.dump(model1, f)
    
    # ==================== MODEL 2: Polynomial Regression ====================
    print("\n2Ô∏è‚É£ Polynomial Regression (deg 2 on PM2.5)...")
    pm2_idx = selected_features.index('pm2_5') if 'pm2_5' in selected_features else 0
    p_coeffs = np.polyfit(X_train_scaled[:, pm2_idx], y_train, 2)
    
    y_train_pred2 = np.polyval(p_coeffs, X_train_scaled[:, pm2_idx])
    y_val_pred2 = np.polyval(p_coeffs, X_val_scaled[:, pm2_idx])
    y_test_pred2 = np.polyval(p_coeffs, X_test_scaled[:, pm2_idx])
    
    mae2_t, rmse2_t, r22_t, mape2_t = calc_metrics(y_train, y_train_pred2)
    mae2_v, rmse2_v, r22_v, mape2_v = calc_metrics(y_val, y_val_pred2)
    mae2, rmse2, r22, mape2 = calc_metrics(y_test, y_test_pred2)
    
    print(f" Train: MAE={mae2_t:.2f}, RMSE={rmse2_t:.2f}, R¬≤={r22_t:.3f}, MAPE={mape2_t:.2f}%")
    print(f" Val:   MAE={mae2_v:.2f}, RMSE={rmse2_v:.2f}, R¬≤={r22_v:.3f}, MAPE={mape2_v:.2f}%")
    print(f" Test:  MAE={mae2:.2f}, RMSE={rmse2:.2f}, R¬≤={r22:.3f}, MAPE={mape2:.2f}% | Gap: {r22_t - r22:.3f}")
    
    results['poly'] = {
        'model': p_coeffs, 'name': 'Polynomial Regression',
        'test_r2': r22, 'test_rmse': rmse2, 'test_mae': mae2, 'test_mape': mape2
    }
    np.save('poly_coeffs.npy', p_coeffs)
    
    # ==================== MODEL 3: PyTorch Linear ====================
    print("\n3Ô∏è‚É£ PyTorch Linear Regressor...")
    
    class LinearModel(nn.Module):
        def __init__(self, input_dim):
            super().__init__()
            self.linear = nn.Linear(input_dim, 1)
        def forward(self, x):
            return self.linear(x)
    
    device = torch.device('cpu')
    X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)
    y_train_t = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)
    X_val_t = torch.tensor(X_val_scaled, dtype=torch.float32)
    X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)
    
    model3 = LinearModel(X_train_scaled.shape[1]).to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model3.parameters(), lr=0.01)
    
    dataset = TensorDataset(X_train_t, y_train_t)
    loader = DataLoader(dataset, batch_size=32, shuffle=True)
    
    for epoch in range(100):
        for batch_x, batch_y in loader:
            optimizer.zero_grad()
            outputs = model3(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
    
    model3.eval()
    with torch.no_grad():
        y_train_pred3 = model3(X_train_t).cpu().numpy().flatten()
        y_val_pred3 = model3(X_val_t).cpu().numpy().flatten()
        y_test_pred3 = model3(X_test_t).cpu().numpy().flatten()
    
    mae3_t, rmse3_t, r23_t, mape3_t = calc_metrics(y_train, y_train_pred3)
    mae3_v, rmse3_v, r23_v, mape3_v = calc_metrics(y_val, y_val_pred3)
    mae3, rmse3, r23, mape3 = calc_metrics(y_test, y_test_pred3)
    
    print(f" Train: MAE={mae3_t:.2f}, RMSE={rmse3_t:.2f}, R¬≤={r23_t:.3f}, MAPE={mape3_t:.2f}%")
    print(f" Val:   MAE={mae3_v:.2f}, RMSE={rmse3_v:.2f}, R¬≤={r23_v:.3f}, MAPE={mape3_v:.2f}%")
    print(f" Test:  MAE={mae3:.2f}, RMSE={rmse3:.2f}, R¬≤={r23:.3f}, MAPE={mape3:.2f}% | Gap: {r23_t - r23:.3f}")
    
    results['pytorch_linear'] = {
        'model': model3, 'name': 'PyTorch Linear',
        'test_r2': r23, 'test_rmse': rmse3, 'test_mae': mae3, 'test_mape': mape3
    }
    torch.save(model3.state_dict(), 'linear_model.pth')
    
    # ==================== MODEL 4: PyTorch MLP ====================
    print("\n4Ô∏è‚É£ PyTorch MLP (increased dropout)...")
    
    class MLP(nn.Module):
        def __init__(self, input_dim):
            super().__init__()
            self.fc1 = nn.Linear(input_dim, 64)
            self.fc2 = nn.Linear(64, 32)
            self.fc3 = nn.Linear(32, 1)
            self.relu = nn.ReLU()
            self.dropout = nn.Dropout(0.3)
        
        def forward(self, x):
            x = self.relu(self.fc1(x))
            x = self.dropout(x)
            x = self.relu(self.fc2(x))
            x = self.dropout(x)
            return self.fc3(x)
    
    model4 = MLP(X_train_scaled.shape[1]).to(device)
    optimizer = optim.Adam(model4.parameters(), lr=0.001)
    
    for epoch in range(100):
        model4.train()
        for batch_x, batch_y in loader:
            optimizer.zero_grad()
            outputs = model4(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
    
    model4.eval()
    with torch.no_grad():
        y_train_pred4 = model4(X_train_t).cpu().numpy().flatten()
        y_val_pred4 = model4(X_val_t).cpu().numpy().flatten()
        y_test_pred4 = model4(X_test_t).cpu().numpy().flatten()
    
    mae4_t, rmse4_t, r24_t, mape4_t = calc_metrics(y_train, y_train_pred4)
    mae4_v, rmse4_v, r24_v, mape4_v = calc_metrics(y_val, y_val_pred4)
    mae4, rmse4, r24, mape4 = calc_metrics(y_test, y_test_pred4)
    
    print(f" Train: MAE={mae4_t:.2f}, RMSE={rmse4_t:.2f}, R¬≤={r24_t:.3f}, MAPE={mape4_t:.2f}%")
    print(f" Val:   MAE={mae4_v:.2f}, RMSE={rmse4_v:.2f}, R¬≤={r24_v:.3f}, MAPE={mape4_v:.2f}%")
    print(f" Test:  MAE={mae4:.2f}, RMSE={rmse4:.2f}, R¬≤={r24:.3f}, MAPE={mape4:.2f}% | Gap: {r24_t - r24:.3f}")
    
    results['mlp'] = {
        'model': model4, 'name': 'PyTorch MLP',
        'test_r2': r24, 'test_rmse': rmse4, 'test_mae': mae4, 'test_mape': mape4
    }
    torch.save(model4.state_dict(), 'mlp_model.pth')
    
    # ==================== MODEL 5: Gradient Boosting ====================
    print("\n5Ô∏è‚É£ Gradient Boosting (stronger reg)...")
    model5 = GradientBoostingRegressor(
        n_estimators=50, max_depth=3, learning_rate=0.05, subsample=0.7,
        min_samples_split=50, min_samples_leaf=20, random_state=42
    )
    model5.fit(X_train, y_train)
    
    y_train_pred5 = model5.predict(X_train)
    y_val_pred5 = model5.predict(X_val)
    y_test_pred5 = model5.predict(X_test)
    
    mae5_t, rmse5_t, r25_t, mape5_t = calc_metrics(y_train, y_train_pred5)
    mae5_v, rmse5_v, r25_v, mape5_v = calc_metrics(y_val, y_val_pred5)
    mae5, rmse5, r25, mape5 = calc_metrics(y_test, y_test_pred5)
    
    print(f" Train: MAE={mae5_t:.2f}, RMSE={rmse5_t:.2f}, R¬≤={r25_t:.3f}, MAPE={mape5_t:.2f}%")
    print(f" Val:   MAE={mae5_v:.2f}, RMSE={rmse5_v:.2f}, R¬≤={r25_v:.3f}, MAPE={mape5_v:.2f}%")
    print(f" Test:  MAE={mae5:.2f}, RMSE={rmse5:.2f}, R¬≤={r25:.3f}, MAPE={mape5:.2f}% | Gap: {r25_t - r25:.3f}")
    
    # CV
    cv_scores5 = []
    for train_idx, val_idx in tscv.split(X_train):
        fold_model = GradientBoostingRegressor(**model5.get_params())
        fold_model.fit(X_train[train_idx], y_train[train_idx])
        fold_pred = fold_model.predict(X_train[val_idx])
        cv_scores5.append(r2_score(y_train[val_idx], fold_pred))
    cv_r2_5 = np.mean(cv_scores5)
    print(f" CV R¬≤: {cv_r2_5:.3f}")
    
    results['gb'] = {
        'model': model5, 'name': 'Gradient Boosting',
        'test_r2': r25, 'test_rmse': rmse5, 'test_mae': mae5, 'test_mape': mape5, 'cv_r2': cv_r2_5
    }
    joblib.dump(model5, 'gb_model.pkl')
    
    # ==================== MODEL 6: XGBoost ====================
    print("\n6Ô∏è‚É£ XGBoost (higher reg)...")
    model6 = xgb.XGBRegressor(
        n_estimators=50, max_depth=3, learning_rate=0.05, subsample=0.7, colsample_bytree=0.7,
        reg_alpha=2.0, reg_lambda=2.0, random_state=42, verbosity=0
    )
    model6.fit(X_train, y_train)
    
    y_train_pred6 = model6.predict(X_train)
    y_val_pred6 = model6.predict(X_val)
    y_test_pred6 = model6.predict(X_test)
    
    mae6_t, rmse6_t, r26_t, mape6_t = calc_metrics(y_train, y_train_pred6)
    mae6_v, rmse6_v, r26_v, mape6_v = calc_metrics(y_val, y_val_pred6)
    mae6, rmse6, r26, mape6 = calc_metrics(y_test, y_test_pred6)
    
    print(f" Train: MAE={mae6_t:.2f}, RMSE={rmse6_t:.2f}, R¬≤={r26_t:.3f}, MAPE={mape6_t:.2f}%")
    print(f" Val:   MAE={mae6_v:.2f}, RMSE={rmse6_v:.2f}, R¬≤={r26_v:.3f}, MAPE={mape6_v:.2f}%")
    print(f" Test:  MAE={mae6:.2f}, RMSE={rmse6:.2f}, R¬≤={r26:.3f}, MAPE={mape6:.2f}% | Gap: {r26_t - r26:.3f}")
    
    cv_scores6 = []
    for train_idx, val_idx in tscv.split(X_train):
        fold_model = xgb.XGBRegressor(**model6.get_params())
        fold_model.fit(X_train[train_idx], y_train[train_idx])
        fold_pred = fold_model.predict(X_train[val_idx])
        cv_scores6.append(r2_score(y_train[val_idx], fold_pred))
    cv_r2_6 = np.mean(cv_scores6)
    print(f" CV R¬≤: {cv_r2_6:.3f}")
    
    results['xgb'] = {
        'model': model6, 'name': 'XGBoost',
        'test_r2': r26, 'test_rmse': rmse6, 'test_mae': mae6, 'test_mape': mape6, 'cv_r2': cv_r2_6
    }
    model6.save_model('xgb_model.json')
    
    # ==================== MODEL 7: Random Forest ====================
    print("\n7Ô∏è‚É£ Random Forest (higher mins)...")
    model7 = RandomForestRegressor(
        n_estimators=50, max_depth=8, min_samples_split=50, min_samples_leaf=20,
        max_features=0.5, random_state=42
    )
    model7.fit(X_train, y_train)
    
    y_train_pred7 = model7.predict(X_train)
    y_val_pred7 = model7.predict(X_val)
    y_test_pred7 = model7.predict(X_test)
    
    mae7_t, rmse7_t, r27_t, mape7_t = calc_metrics(y_train, y_train_pred7)
    mae7_v, rmse7_v, r27_v, mape7_v = calc_metrics(y_val, y_val_pred7)
    mae7, rmse7, r27, mape7 = calc_metrics(y_test, y_test_pred7)
    
    print(f" Train: MAE={mae7_t:.2f}, RMSE={rmse7_t:.2f}, R¬≤={r27_t:.3f}, MAPE={mape7_t:.2f}%")
    print(f" Val:   MAE={mae7_v:.2f}, RMSE={rmse7_v:.2f}, R¬≤={r27_v:.3f}, MAPE={mape7_v:.2f}%")
    print(f" Test:  MAE={mae7:.2f}, RMSE={rmse7:.2f}, R¬≤={r27:.3f}, MAPE={mape7:.2f}% | Gap: {r27_t - r27:.3f}")
    
    cv_scores7 = []
    for train_idx, val_idx in tscv.split(X_train):
        fold_model = RandomForestRegressor(**model7.get_params())
        fold_model.fit(X_train[train_idx], y_train[train_idx])
        fold_pred = fold_model.predict(X_train[val_idx])
        cv_scores7.append(r2_score(y_train[val_idx], fold_pred))
    cv_r2_7 = np.mean(cv_scores7)
    print(f" CV R¬≤: {cv_r2_7:.3f}")
    
    results['rf'] = {
        'model': model7, 'name': 'Random Forest',
        'test_r2': r27, 'test_rmse': rmse7, 'test_mae': mae7, 'test_mape': mape7, 'cv_r2': cv_r2_7
    }
    joblib.dump(model7, 'rf_model.pkl')
    
    # Summary
    print("\n" + "="*70)
    print("TRAINING SUMMARY (Test Metrics)")
    print("="*70)
    results_summary = pd.DataFrame([
        {'Model': res['name'], 'Test MAE': res['test_mae'], 'Test RMSE': res['test_rmse'],
         'Test R¬≤': res['test_r2'], 'Test MAPE (%)': res['test_mape'], 'CV R¬≤': res.get('cv_r2', np.nan)}
        for res in results.values()
    ]).sort_values('Test R¬≤', ascending=False)
    
    print(results_summary.to_string(index=False, float_format='%.3f'))
    results_summary.to_csv('training_results.csv', index=False)
    print("\n‚úÖ Training complete!")
    
    return results

# =============================================================================
# MAIN EXECUTION
# =============================================================================
if __name__ == "__main__":
    # Fetch data
    df_feat = fetch_from_hopsworks(feature_group_name="aqi_features", version=1, for_training=True)
    
    # Prepare data
    (X_train, X_val, X_test, y_train, y_val, y_test,
     X_train_scaled, X_val_scaled, X_test_scaled, selected_features) = prepare_data(df_feat)
    
    # Train all models
    results = train_all_models(
        X_train, X_val, X_test, y_train, y_val, y_test,
        X_train_scaled, X_val_scaled, X_test_scaled, selected_features
    )
    
    print("\n" + "="*70)
    print("‚úÖ TRAINING PIPELINE COMPLETE!")
    print("="*70)
    print("\nSaved Models:")
    print("  - linear_model.pkl")
    print("  - poly_coeffs.npy")
    print("  - linear_model.pth")
    print("  - mlp_model.pth")
    print("  - gb_model.pkl")
    print("  - xgb_model.json")
    print("  - rf_model.pkl")
    print("  - scaler.pkl")
    print("  - selected_features.json")
    print("  - training_results.csv")
